{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Stable-Diffusion/blob/main/StableDiffusion2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate seamless textures with Stable Diffusion using in-painting\n",
        "\n",
        "By [Travis Hoppe](https://twitter.com/metasemantic/status/1568450612924420096). This uses the CompVis SD [checkpoint](https://github.com/CompVis/stable-diffusion) provided by [HuggingFace](https://huggingface.co/CompVis/stable-diffusion-v1-4).\n",
        "\n",
        "\n",
        "+ _Version 0.1.1 (bug fix from [@PhiMarHal](https://twitter.com/PhiMarHal/status/1569047664855240704))_\n",
        "+ _Version 0.1.0 Initial release_"
      ],
      "metadata": {
        "id": "9887g-n0Bfla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the GPU, this generally requires a 16 GB card\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "HnJ370SCBaAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "! pip install --upgrade Pillow==9.0.0\n",
        "! pip install --quiet torch numpy diffusers transformers ftfy"
      ],
      "metadata": {
        "id": "lX9xGvgACFeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the above cell says \"You must restart the runtime in order to use newly installed versions.\" click `Runtime` -> `Restart Runtime`. For the code to work, the version below must output 9.0.0"
      ],
      "metadata": {
        "id": "9tv6ANB-xFQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.__version__"
      ],
      "metadata": {
        "id": "4kECYk5ZwJvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You'll need a login to access the model, do this here\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "7xD4IhdBDJsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "TIvSVge-EgcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "from transformers.trainer_utils import set_seed\n",
        "\n",
        "# make sure you're logged in with `huggingface-cli login`\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    model_id, use_auth_token=True,\n",
        "    torch_dtype=torch.float16, revision=\"fp16\",).to(\"cuda\")\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "avksM5dOChLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model 2\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "pipe2 = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id, \n",
        "    set_auth_token=True,\n",
        "    torch_dtype=torch.float16, revision=\"fp16\",\n",
        ")\n",
        "pipe2 = pipe2.to(\"cuda\")"
      ],
      "metadata": {
        "id": "uv4F3Eg0OO-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code to get it to work \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def circle_mask(img):\n",
        "    \"\"\"Roll the images 50% vertical and horz and mask the new center for in-fill\"\"\"\n",
        "    w, h = img.size\n",
        "    x = np.roll(np.roll(np.array(img), h // 2, 0), w // 2, 1)\n",
        "\n",
        "    img2 = Image.fromarray(x)\n",
        "    mask = Image.fromarray(np.zeros_like(x)[:, :, 0])\n",
        "\n",
        "    draw = ImageDraw.Draw(mask)\n",
        "    coords = [(w / 2, 0), (w, h / 2), (w / 2, h), (0, h / 2)]\n",
        "    draw.polygon(coords, fill=255)\n",
        "\n",
        "    return img2, mask\n",
        "\n",
        "@torch.no_grad()\n",
        "def seeded_random_latent(seed, in_channels=4, height=512, width=512):\n",
        "    set_seed(seed)\n",
        "    device = \"cuda\"\n",
        "    batch_size = 1\n",
        "\n",
        "    latents = torch.randn(\n",
        "        (batch_size, in_channels, height // 8, width // 8),\n",
        "        generator=None,\n",
        "        device=device,\n",
        "    )\n",
        "    return latents\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(prompt, seed):\n",
        "    width, height = 512, 512\n",
        "\n",
        "    z0 = seeded_random_latent(seed)\n",
        "\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        img0 = pipe2(prompt, latents=z0, height=height, width=width)[\"sample\"][0]\n",
        "\n",
        "    return img0\n",
        "\n",
        "@torch.no_grad()\n",
        "def seamless_diffusion(prompt, seed, circle_strength=0.50, input_image=None):\n",
        "\n",
        "    if input_image is None:\n",
        "      img0 = generate(prompt, seed)\n",
        "    else:\n",
        "      img0 = input_image.resize((512, 512))\n",
        "    img1, mask = circle_mask(img0)\n",
        "\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        img2 = pipe(\n",
        "            prompt=prompt, init_image=img1, mask_image=mask, strength=circle_strength\n",
        "        )[\"sample\"][0]\n",
        "    return img2\n",
        "\n",
        "def combine_images_w(imgs):\n",
        "    widths = [x.width for x in imgs]\n",
        "    h = imgs[0].height\n",
        "\n",
        "    img = Image.new(\"RGB\", (sum(widths), h))\n",
        "    img.paste(imgs[0], (0, 0))\n",
        "    w = imgs[0].width\n",
        "\n",
        "    for k in range(1, len(imgs)):\n",
        "        img.paste(imgs[k], (w, 0))\n",
        "        w += imgs[k - 1].width\n",
        "\n",
        "    return img\n",
        "\n",
        "def combine_images_h(imgs):\n",
        "    heights = [x.height for x in imgs]\n",
        "    w = imgs[0].width\n",
        "\n",
        "    img = Image.new(\"RGB\", (w, sum(heights)))\n",
        "\n",
        "    img.paste(imgs[0], (0, 0))\n",
        "    h = imgs[0].height\n",
        "\n",
        "    for k in range(1, len(imgs)):\n",
        "        img.paste(imgs[0], (0, h))\n",
        "        h += imgs[k - 1].width\n",
        "\n",
        "    return img\n",
        "\n",
        "def four_stack(img):\n",
        "    row = combine_images_w([img, img])\n",
        "    return combine_images_h([row, row])\n",
        "\n",
        "# Uncomment these lines to turn off the NSFW filter at your own risk.\n",
        "#def dummy(images, **kwargs):\n",
        "#  return images, False\n",
        "#pipe.safety_checker = dummy\n",
        "#pipe2.safety_checker = dummy"
      ],
      "metadata": {
        "id": "WU3fAHi8DIhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "seed = 48\n",
        "prompt = \"High resolution photograph of hundreds of coffee beans\"\n",
        "\n",
        "# High strength better blending, but a good chance to see a \"diamond\" artifact\n",
        "strength = 0.50\n",
        "\n",
        "img = seamless_diffusion(prompt, seed, strength)\n",
        "display(img)"
      ],
      "metadata": {
        "id": "Ufm7wHkGCzAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out how it looks like tiled 4x4\n",
        "display(four_stack(img).resize((512,512)))"
      ],
      "metadata": {
        "id": "7FqRAN5oNwDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out how it looks like tiled 16 by 16! \n",
        "img4 = four_stack(img)\n",
        "display(four_stack(img4).resize((512,512)))"
      ],
      "metadata": {
        "id": "V0nVCozWRL9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}